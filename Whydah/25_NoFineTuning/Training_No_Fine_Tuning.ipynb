{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZvwlHTgDWMO"
   },
   "source": [
    "# Training example for pin-tailed whydah (25 samples) while freezing the feature extractor\n",
    "\n",
    "\n",
    "**Paper:** Passive Acoustic Monitoring and Transfer Learning\n",
    "\n",
    "**Authors:** Emmanuel Dufourq, Carly Batist, Ruben Foquet and Ian Durbach\n",
    "\n",
    "**Repository:** https://github.com/emmanueldufourq/PAM_TransferLearning\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Note 1: Set colab=True if executing on Google Colab, or set colab=False if running locally.**\n",
    "\n",
    "**Note 2: When running on Google Colab, please select Runtime > Change runtime type > GPU**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pV-HZWUkBjv"
   },
   "source": [
    "## Step 0: Download data and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do70uZrF_l3w"
   },
   "outputs": [],
   "source": [
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWcJJ738DhMx"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install SoundFile\n",
    "    from google.colab import drive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    import zipfile\n",
    "\n",
    "    # Google Authentication\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    # Download code files\n",
    "    downloaded = drive.CreateFile({'id':\"1_4HsmtLfGrIUbO6-ILnbtKxoLH2DEncw\"})\n",
    "    downloaded.GetContentFile('Code.zip')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with zipfile.ZipFile('Code.zip', 'r') as zip_file:\n",
    "        zip_file.extractall()\n",
    "\n",
    "    # Download data files\n",
    "    downloaded = drive.CreateFile({'id':\"1ZA5gnuREO2pqhs69QRSn-LlG8DSn1JhO\"})\n",
    "    downloaded.GetContentFile('Data.zip')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with zipfile.ZipFile('Data.zip', 'r') as zip_file:\n",
    "        zip_file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1OyZ2AoDhRE"
   },
   "outputs": [],
   "source": [
    "from Preprocessing import *\n",
    "from TrainHelper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPvrr__qEHyN"
   },
   "source": [
    "## Step 1: Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVgTsO3EDhTm"
   },
   "outputs": [],
   "source": [
    "species_folder = 'Data' # Should contain /Audio and /Annotations\n",
    "lowpass_cutoff = 9000 # Cutt off for low pass filter\n",
    "downsample_rate = 18400 # Frequency to downsample to\n",
    "nyquist_rate = 9200 # Nyquist rate (half of sampling rate)\n",
    "segment_duration = 3 # how long should a segment be\n",
    "augmentation_amount_positive_class = 1 # how many times should a segment be augmented\n",
    "augmentation_amount_negative_class = 1 # how many times should a segment be augmented\n",
    "positive_class = ['PTW']\n",
    "negative_class = ['NOISE'] # which labels should be considered as background noise (also species not of interest)\n",
    "audio_extension = '.WAV'\n",
    "file_type = 'svl'\n",
    "n_fft = 1024 # Hann window length\n",
    "hop_length = 256 # Sepctrogram hop size\n",
    "n_mels = 128 # Spectrogram number of mells\n",
    "f_min = 1500 # Spectrogram, minimum frequency for call\n",
    "f_max = 10000 # Spectrogram, maximum frequency for call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIAL-ZF8j6U9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_pro = Preprocessing(species_folder, lowpass_cutoff, \n",
    "                downsample_rate, nyquist_rate, \n",
    "                segment_duration,\n",
    "                positive_class, negative_class, \n",
    "                augmentation_amount_positive_class, \n",
    "                augmentation_amount_negative_class,n_fft, \n",
    "                hop_length, n_mels, f_min, f_max, file_type, \n",
    "                audio_extension)\n",
    "\n",
    "X_calls, Y_calls = pre_pro.create_dataset(False)\n",
    "\n",
    "pre_pro.save_data_to_pickle(X_calls, Y_calls)\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UduB6bNvi6yJ"
   },
   "source": [
    "## Step 2: Determine augmentation required\n",
    "\n",
    "Look how many precense and absence examples are in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlEs7KL3i0j0"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(Y_calls, return_counts=True)\n",
    "original_distribution = dict(zip(unique, counts))\n",
    "print('Data distribution:',original_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg__ita8cR0k"
   },
   "source": [
    "## Step 3: Set the augmentation amount\n",
    "\n",
    "For this experiment, take the number of absence events and divide by the sample size. In this case 25. So 25 samples will be randomly selected and then augmented a number of times (```augmentation_amount```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nM_JNJbjBb4"
   },
   "outputs": [],
   "source": [
    "augmentation_amount = int(610/25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs2zn2oRjCbC"
   },
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeyEG5NFb89y"
   },
   "outputs": [],
   "source": [
    "sample_size = 25\n",
    "INPUT_SHAPE = (128,216, 3)\n",
    "EPOCHS = 5\n",
    "save_results_folder = 'Data/Model_Output'\n",
    "initialise_distribution = {'NOISE':0, 'PTW':0}\n",
    "number_classes = 2\n",
    "call_order = ['NOISE','PTW'] #First element will be labelled as 0 and next as 1 etc...\n",
    "seed = 2564512\n",
    "\n",
    "model_resnet152v2 = train_model('ResNet152V2', species_folder, augmentation_amount, \n",
    "                                seed, call_order, INPUT_SHAPE, sample_size,save_results_folder, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns55MSg0oZeq"
   },
   "source": [
    "### The model file can be around in /Data/Model_Output/ and place this .hdf5 into the root folder where the code is located (e.g. same location in ```Predicting_No_Fine_Tuning.ipynb```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6oALDHDx7VO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN41GANw43ZhlMNxTz+f6U5",
   "collapsed_sections": [],
   "name": "Training_No_Fine_Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
