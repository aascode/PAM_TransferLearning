{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk2cS1GxHktq"
   },
   "source": [
    "# Prediction example for pin-tailed whydah (25 samples) while fine-tuning the feature extractor\n",
    "\n",
    "\n",
    "**Paper:** Passive Acoustic Monitoring and Transfer Learning\n",
    "\n",
    "**Authors:** Emmanuel Dufourq, Carly Batist, Ruben Foquet and Ian Durbach\n",
    "\n",
    "**Repository:** https://github.com/emmanueldufourq/PAM_TransferLearning\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Note 1: Set colab=True if executing on Google Colab, or set colab=False if running locally.**\n",
    "\n",
    "**Note 2: When running on Google Colab, please select Runtime > Change runtime type > GPU**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVKfnztFHsxN"
   },
   "source": [
    "## Step 0: Download data and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yA2c6YvLJOcM"
   },
   "outputs": [],
   "source": [
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3xr_1YkJOei"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install SoundFile\n",
    "    from google.colab import drive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    import zipfile\n",
    "\n",
    "    # Google Authentication\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    # Download model files\n",
    "    downloaded = drive.CreateFile({'id':\"1cjP8acMaIJvNMoLF1Fbg35QRkWq33ZTm\"})\n",
    "    downloaded.GetContentFile('2564514-ResNet152V2_FineTuned_Whydah.hdf5')\n",
    "\n",
    "    # Download data files\n",
    "    downloaded = drive.CreateFile({'id':\"1ZA5gnuREO2pqhs69QRSn-LlG8DSn1JhO\"})\n",
    "    downloaded.GetContentFile('Data.zip')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with zipfile.ZipFile('Data.zip', 'r') as zip_file:\n",
    "        zip_file.extractall()\n",
    "\n",
    "    # Download code files\n",
    "    downloaded = drive.CreateFile({'id':\"1NhGJqUKT3aGqYIBnIFXeav_6fTxqfAog\"})\n",
    "    downloaded.GetContentFile('Code.zip')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with zipfile.ZipFile('Code.zip', 'r') as zip_file:\n",
    "        zip_file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3A0NQCHGxaJ"
   },
   "outputs": [],
   "source": [
    "!pip install yattag\n",
    "from PredictionHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvWaLtx4Em2o"
   },
   "outputs": [],
   "source": [
    "species_folder = 'Data' # Should contain /Audio and /Annotations\n",
    "lowpass_cutoff = 9000 # Cutt off for low pass filter\n",
    "downsample_rate = 18400 # Frequency to downsample to\n",
    "nyquist_rate = 9200 # Nyquist rate (half of sampling rate)\n",
    "segment_duration = 3 # how long should a segment be\n",
    "augmentation_amount_positive_class = 1 # how many times should a segment be augmented\n",
    "augmentation_amount_negative_class = 1 # how many times should a segment be augmented\n",
    "positive_class = ['PTW']\n",
    "negative_class = ['NOISE'] # which labels should be considered as background noise (also species not of interest)\n",
    "n_fft = 1024 # Hann window length\n",
    "hop_length = 256 # Sepctrogram hop size\n",
    "n_mels = 128 # Spectrogram number of mells\n",
    "f_min = 1500 # Spectrogram, minimum frequency for call\n",
    "f_max = 10000 # Spectrogram, maximum frequency for call\n",
    "weights_name = '2564514-ResNet152V2_FineTuned_Whydah.hdf5' # Name of the TF NN weights to load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mOrjOa9Hvwj"
   },
   "source": [
    "## Step 1: Predict on each testing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daXzVW3qEm48"
   },
   "outputs": [],
   "source": [
    "predict = Prediction(species_folder, lowpass_cutoff, \n",
    "                downsample_rate, nyquist_rate, \n",
    "                segment_duration,\n",
    "                positive_class, negative_class, \n",
    "                augmentation_amount_positive_class, \n",
    "                augmentation_amount_negative_class,n_fft, \n",
    "                hop_length, n_mels, f_min, f_max, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCuUv7_zKShW"
   },
   "outputs": [],
   "source": [
    "predict.predict_all_test_files(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdmx_FyHHzcd"
   },
   "source": [
    "## Step 2: Download .svl files from ```Data/Model_Output/``` and import into SonicVisualiser to visualise the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHt93DHDKFmq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO1FIViRzAmIPczbF3/Xp7g",
   "collapsed_sections": [],
   "name": "Predicting_Fine_Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
